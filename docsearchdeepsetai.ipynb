{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:haystack.utils.doc_store:Tried to start Elasticsearch through Docker but this failed. It is likely that there is already an existing Elasticsearch instance running. \n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import launch_es\n",
    "launch_es()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:elasticsearch:GET http://152.67.165.13:9200/ [status:N/A request:21.290s]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py\", line 169, in _new_conn\n",
      "    conn = connection.create_connection(\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\connection.py\", line 96, in create_connection\n",
      "    raise err\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\connection.py\", line 86, in create_connection\n",
      "    sock.connect(sa)\n",
      "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\elasticsearch\\connection\\http_urllib3.py\", line 255, in perform_request\n",
      "    response = self.pool.urlopen(\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py\", line 755, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\util\\retry.py\", line 507, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\packages\\six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connectionpool.py\", line 394, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py\", line 234, in request\n",
      "    super(HTTPConnection, self).request(method, url, body=body, headers=headers)\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\", line 1255, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\", line 1301, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\", line 1250, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\", line 1010, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\http\\client.py\", line 950, in send\n",
      "    self.connect()\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py\", line 200, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"c:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\urllib3\\connection.py\", line 181, in _new_conn\n",
      "    raise NewConnectionError(\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000020224A984C0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "Initial connection to Elasticsearch failed. Make sure you run an Elasticsearch instance at `[{'host': '152.67.165.13', 'port': 9200}]` and that it has finished the initial ramp up (can take > 30s).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\haystack\\document_stores\\elasticsearch.py\u001b[0m in \u001b[0;36m_init_elastic_client\u001b[1;34m(cls, host, port, username, password, api_key_id, api_key, aws4auth, scheme, ca_certs, verify_certs, timeout, use_system_proxy)\u001b[0m\n\u001b[0;32m    274\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m                     raise ConnectionError(\n\u001b[0m\u001b[0;32m    276\u001b[0m                         \u001b[1;34mf\"Initial connection to Elasticsearch failed. Make sure you run an Elasticsearch instance \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: Initial connection to Elasticsearch failed. Make sure you run an Elasticsearch instance at `[{'host': '152.67.165.13', 'port': 9200}]` and that it has finished the initial ramp up (can take > 30s).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-e2265f236ec8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ELASTICSEARCH_HOST\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"152.67.165.13\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m document_store = ElasticsearchDocumentStore(\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0musername\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\haystack\\nodes\\base.py\u001b[0m in \u001b[0;36mwrapper_exportable_to_yaml\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m# Call the actuall __init__ function with all the arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0minit_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper_exportable_to_yaml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\haystack\\document_stores\\elasticsearch.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, host, port, username, password, api_key_id, api_key, aws4auth, index, label_index, search_fields, content_field, name_field, embedding_field, embedding_dim, custom_mapping, excluded_meta_data, analyzer, scheme, ca_certs, verify_certs, recreate_index, create_index, refresh_type, similarity, timeout, return_embedding, duplicate_documents, index_type, scroll, skip_missing_embeddings, synonyms, synonym_type, use_system_proxy)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;31m# Base constructor might need the client to be ready, create it first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         client = self._init_elastic_client(\n\u001b[0m\u001b[0;32m    144\u001b[0m             \u001b[0mhost\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rohit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\haystack\\document_stores\\elasticsearch.py\u001b[0m in \u001b[0;36m_init_elastic_client\u001b[1;34m(cls, host, port, username, password, api_key_id, api_key, aws4auth, scheme, ca_certs, verify_certs, timeout, use_system_proxy)\u001b[0m\n\u001b[0;32m    278\u001b[0m                     )\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             raise ConnectionError(\n\u001b[0m\u001b[0;32m    281\u001b[0m                 \u001b[1;34mf\"Initial connection to Elasticsearch failed. Make sure you run an Elasticsearch instance at `{hosts}` and that it has finished the initial ramp up (can take > 30s).\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             )\n",
      "\u001b[1;31mConnectionError\u001b[0m: Initial connection to Elasticsearch failed. Make sure you run an Elasticsearch instance at `[{'host': '152.67.165.13', 'port': 9200}]` and that it has finished the initial ramp up (can take > 30s)."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "# Get the host where Elasticsearch is running, default to localhost\n",
    "host = os.environ.get(\"ELASTICSEARCH_HOST\", \"152.67.165.13\")\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    host=host,\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    index=\"document\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from haystack.document_stores import InMemoryDocumentStore\n",
    "\n",
    "# document_store = InMemoryDocumentStore(use_bm25=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = r\"zui\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:haystack.utils.preprocessing:Converting zui\\glcoa_test_cases.txt\n",
      "INFO:haystack.utils.preprocessing:Converting zui\\New-ConvertRite_Installation_Guide_Ver(1.2) (1).docx\n",
      "INFO:haystack.utils.preprocessing:Converting zui\\RiteSync Guide_new.docx\n",
      "INFO:haystack.utils.preprocessing:Converting zui\\Revised ConvertRite User Manual - New_V3.pdf\n",
      "Preprocessing:   0%|          | 0/4 [00:00<?, ?docs/s]WARNING:haystack.nodes.preprocessor.preprocessor:We found one or more sentences whose word count is higher than the split length.\n",
      "Preprocessing: 100%|██████████| 4/4 [00:00<00:00, 123.67docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_files_input: 4\n",
      "n_docs_output: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import convert_files_to_docs\n",
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "\n",
    "all_docs = convert_files_to_docs(dir_path=doc_dir)\n",
    "preprocessor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=False,\n",
    "    split_by=\"word\",\n",
    "    split_length=100,\n",
    "    split_respect_sentence_boundary=True,\n",
    ")\n",
    "docs = preprocessor.process(all_docs)\n",
    "\n",
    "print(f\"n_files_input: {len(all_docs)}\\nn_docs_output: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import FAISSDocumentStore\n",
    "\n",
    "\n",
    "document_store = FAISSDocumentStore(sql_url=\"sqlite://\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n",
      "INFO:haystack.nodes.retriever.dense:Init retriever using embeddings of model sentence-transformers/multi-qa-mpnet-base-dot-v1\n",
      "WARNING:haystack.document_stores.faiss:Calling DocumentStore.update_embeddings() on an empty index\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import EmbeddingRetriever\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\",\n",
    "    model_format=\"sentence_transformers\",\n",
    ")\n",
    "# Important:\n",
    "# Now that we initialized the Retriever, we need to call update_embeddings() to iterate over all\n",
    "# previously indexed documents and update their embedding representation.\n",
    "# While this can be a time consuming operation (depending on the corpus size), it only needs to be done once.\n",
    "# At query time, we only need to embed the query and compare it to the existing document embeddings, which is very fast.\n",
    "document_store.update_embeddings(retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Documents: 10000it [00:00, 54486.27it/s]         \n",
      "INFO:haystack.document_stores.faiss:Updating embeddings for 49 docs...\n",
      "Updating Embedding:   0%|          | 0/49 [00:00<?, ? docs/s]INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "Batches: 100%|██████████| 2/2 [01:03<00:00, 31.74s/it]\n",
      "Documents Processed: 10000 docs [01:03, 157.12 docs/s]        \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write documents to document store\n",
    "document_store.write_documents(docs)\n",
    "\n",
    "# Add documents embeddings to index\n",
    "document_store.update_embeddings(retriever=retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n",
      "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n",
      "INFO:haystack.modeling.model.language_model: * LOADING MODEL: 'deepset/roberta-base-squad2' (Roberta)\n",
      "INFO:haystack.modeling.model.language_model:Auto-detected model language: english\n",
      "INFO:haystack.modeling.model.language_model:Loaded 'deepset/roberta-base-squad2' (Roberta model) from model hub.\n",
      "INFO:haystack.modeling.utils:Using devices: CPU - Number of GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import FARMReader\n",
    "\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "pipe = ExtractiveQAPipeline(reader, retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.02it/s]\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "INFO:haystack.schema:Setting the ID manually. This might cause a mismatch with the ID that would be generated from the document content and id_hash_keys value.\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:06<00:00,  6.83s/ Batches]\n"
     ]
    }
   ],
   "source": [
    "prediction = pipe.run(\n",
    "    query=\"what is pod\",\n",
    "    params={\n",
    "        \"Retriever\": {\"top_k\": 10},\n",
    "        \"Reader\": {\"top_k\": 5}\n",
    "    }\n",
    ")\n",
    "# You can configure how many candidates the reader and retriever shall return\n",
    "# The higher top_k for retriever, the better (but also the slower) your answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'what is pod', 'no_ans_gap': 6.876414775848389, 'answers': [<Answer {'answer': 'independent', 'type': 'extractive', 'score': 0.7736260294914246, 'context': 'earch for POD – click on add at lookup values – add POD\\nname. (POD is independent- doesn’t rely on any other values) – save.\\n➢ Export CSV – Export CSV', 'offsets_in_document': [{'start': 250, 'end': 261}], 'offsets_in_context': [{'start': 70, 'end': 81}], 'document_id': '79046f7fe6c4675b2c84937edcb9a2dc', 'meta': {'name': 'Revised ConvertRite User Manual - New_V3.pdf', '_split_id': 2, 'vector_id': '21'}}>, <Answer {'answer': 'Product Oriented Delivery', 'type': 'extractive', 'score': 0.19494059681892395, 'context': 'ject code) are\\nMaster data.\\nSTEP 1:\\nCreation of POD:\\nPOD - The Product Oriented Delivery (POD) model is a software development strategy that centers o', 'offsets_in_document': [{'start': 392, 'end': 417}], 'offsets_in_context': [{'start': 63, 'end': 88}], 'document_id': '8d6b2472231e05f21e8128d114eef203', 'meta': {'name': 'Revised ConvertRite User Manual - New_V3.pdf', '_split_id': 1, 'vector_id': '24'}}>, <Answer {'answer': 'Project', 'type': 'extractive', 'score': 0.1490289866924286, 'context': 'left- admin – role object.\\x0c- User Manual | Confidential Page | 8\\n• Select the role name as admin, required POD, Project, parent object – Enable flag. ', 'offsets_in_document': [{'start': 470, 'end': 477}], 'offsets_in_context': [{'start': 112, 'end': 119}], 'document_id': '4277b3f40210d6af1b2ed1b904aeb9bb', 'meta': {'name': 'Revised ConvertRite User Manual - New_V3.pdf', '_split_id': 6, 'vector_id': '8'}}>, <Answer {'answer': 'Project is related to POD – Hence select the required POD – Save', 'type': 'extractive', 'score': 0.12335778027772903, 'context': 's.\\x0c- User Manual | Confidential Page | 5\\n• Project is related to POD – Hence select the required POD – Save.\\nCreation of Parent Object:\\n• Click on the', 'offsets_in_document': [{'start': 196, 'end': 260}], 'offsets_in_context': [{'start': 43, 'end': 107}], 'document_id': 'a1db2faa2ef5046e8aa71667f2344d76', 'meta': {'name': 'Revised ConvertRite User Manual - New_V3.pdf', '_split_id': 3, 'vector_id': '30'}}>, <Answer {'answer': 'Copy project', 'type': 'extractive', 'score': 0.0908258706331253, 'context': 'onment will be assigned to the\\nproject and object in this screen).\\n➢ Copy project is used to copy the complete project with same data into a different', 'offsets_in_document': [{'start': 142, 'end': 154}], 'offsets_in_context': [{'start': 69, 'end': 81}], 'document_id': 'f767f5a5e3d5c937fc1f58cc8b71621', 'meta': {'name': 'Revised ConvertRite User Manual - New_V3.pdf', '_split_id': 5, 'vector_id': '47'}}>], 'documents': [<Document: {'content': 'High Level Process Flow\\nLogin Information\\nLink: https://convertrite.ritesoftware.com/\\nLogin: The user should log in and select the role of admin to access ConvertRite.\\x0c- User Manual | Confidential Page | 4\\nWorkflow\\nClick on hamburger menu on top left\\nfor application navigation.\\n➢ Project, POD, Parent object and child object (object code) are\\nMaster data.\\nSTEP 1:\\nCreation of POD:\\nPOD - The Product Oriented Delivery (POD) model is a software development strategy that centers on\\nbuilding small cross-functional teams that own specific tasks or requirements for a project.\\n', 'content_type': 'text', 'score': 0.5552377326900567, 'meta': {'name': 'Revised ConvertRite User Manual - New_V3.pdf', '_split_id': 1, 'vector_id': '24'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '8d6b2472231e05f21e8128d114eef203'}>, <Document: {'content': '• Define project name, POD and all mandatory information- save (POD environment will be assigned to the\\nproject and object in this screen).\\n➢ Copy project is used to copy the complete project with same data into a different POD with project\\nstatus, start and completion date.\\x0c- User Manual | Confidential Page | 7\\n• Click on Load WBS – Project will be assigned to parent object.\\n', 'content_type': 'text', 'score': 0.5537212064523289, 'meta': {'name': 'Revised ConvertRite User Manual - New_V3.pdf', '_split_id': 5, 'vector_id': '47'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'f767f5a5e3d5c937fc1f58cc8b71621'}>, <Document: {'content': 'Creation of Project:\\n• To create the project, in the lookup header – search for the Lookup name as Project and add the Lookup\\nvalue – your project details.\\x0c- User Manual | Confidential Page | 5\\n• Project is related to POD – Hence select the required POD – Save.\\nCreation of Parent Object:\\n• Click on the hamburger button - Master data - Lookup workbench.\\n• Click on Search -Search for Parent object- add a lookup value- define lookup name as required parent\\nobject from FBDI file (Create parent object) – Assign project name in actual value.\\n', 'content_type': 'text', 'score': 0.5461794250131893, 'meta': {'name': 'Revised ConvertRite User Manual - New_V3.pdf', '_split_id': 3, 'vector_id': '30'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'a1db2faa2ef5046e8aa71667f2344d76'}>, <Document: {'content': '• If the project is not listed under actual value, need to add project details under project name lookup name.\\x0c- User Manual | Confidential Page | 6\\nCreation of Child Object:\\n• Search for lookup name – object code – add the lookup value for child object from FBDI file which should\\nbe related to the parent object code.\\nStep 2:\\nAssign POD and Project:\\n• Click on the Hamburger button –ConvertRite – Manage your project – New.\\n', 'content_type': 'text', 'score': 0.5446764144953562, 'meta': {'name': 'Revised ConvertRite User Manual - New_V3.pdf', '_split_id': 4, 'vector_id': '38'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ce3ff407c698aee733196d8c34280af0'}>, <Document: {'content': 'A project can be created in different PODs or many Projects in one POD can be\\ncreated.\\n• To create a POD in ConvertRite, click on hamburger button- master data-\\nlookup workbench- search for POD – click on add at lookup values – add POD\\nname. (POD is independent- doesn’t rely on any other values) – save.\\n➢ Export CSV – Export CSV button downloads all the file based data on this\\nparticular screen.\\n', 'content_type': 'text', 'score': 0.5440909735213707, 'meta': {'name': 'Revised ConvertRite User Manual - New_V3.pdf', '_split_id': 2, 'vector_id': '21'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '79046f7fe6c4675b2c84937edcb9a2dc'}>, <Document: {'content': '• If the project is created already, search for the required project and Load WBS [it can be done for the\\nother parent object (Load WBS is parent object level)]\\nStep 3:\\nAssign Role Object:\\n• We must Enable flag to activate the load metadata option.\\n• Click on the Admin – switch to SuperUser.\\n• In the SuperUser profile, click on the hamburger button on top left- admin – role object.\\x0c- User Manual | Confidential Page | 8\\n• Select the role name as admin, required POD, Project, parent object – Enable flag. ', 'content_type': 'text', 'score': 0.5426735225517835, 'meta': {'name': 'Revised ConvertRite User Manual - New_V3.pdf', '_split_id': 6, 'vector_id': '8'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '4277b3f40210d6af1b2ed1b904aeb9bb'}>, <Document: {'content': 'Create the unit file for zookeeper:\\n\\n$ sudo vi  /etc/systemd/system/zookeeper.service\\n\\nEnter the following unit definition into the file:\\n\\nCreate the unit file for Kafka:\\n\\n$ sudo vi  /etc/systemd/system/kafka.service\\n\\nEnter the following unit definition into the file:\\n\\nNow that you have defined the units, start Kafka and zookeeper with the following commands.\\n\\n', 'content_type': 'text', 'score': 0.5305109648127471, 'meta': {'name': 'RiteSync Guide_new.docx', '_split_id': 3, 'vector_id': '16'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '67b05ec7831ddb39e0b0673cbd58ea11'}>, <Document: {'content': 'Now that you’ve configured Kafka.\\n\\nNow change the “datadir” path in “zookeeper.properties file\\n\\n$ vi /home/ritesync/kafka/config/zookeeper.properties\\n\\n~/home/ritesync/kafka/config/zookeeper.properties\\n\\ndataDir=/home/ritesync/kafka/zookeeper\\n\\nCreating Systemd Unit Files and Starting the Kafka Server\\n\\nIn this section, you will create systemd unit files for the Kafka service. This will help you perform common service actions such as starting, stopping, and restarting Kafka in a manner consistent with other Linux services.\\n\\nZookeeper is a service that Kafka uses to manage its cluster state and configurations. It is used in many distributed systems.\\n\\n', 'content_type': 'text', 'score': 0.5303332546697819, 'meta': {'name': 'RiteSync Guide_new.docx', '_split_id': 2, 'vector_id': '39'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'd613253e3446a83fa5513fecfbe40e74'}>, <Document: {'content': 'This will helps you to perform common service actions such as starting, stopping, and restarting ritesync, cloud integrator and loader service JARS  in a manner consistent with other Linux services.\\nCreate a directory as “service-scripts”\\n\\n$ mkdir /home/ritesync/service-scripts\\n\\nNow create a bash script file in /home/ritesync/service-scripts for ritesync service.\\n\\n$ vi /home/ritesync/service-scripts/ritesync.sh\\n\\nSave and exit the file.\\n\\n$ chmod 777 /home/ritesync/service-scripts/ritesync.sh\\n\\nCreate the unit file for RITESYNC:\\n\\n$ sudo vi /etc/systemd/system/ritesync.service\\n\\nEnter the following unit definition into the file:\\n\\nSave and exit the file.\\n\\nNow start the Ritesync service.\\n\\n', 'content_type': 'text', 'score': 0.5296930057189191, 'meta': {'name': 'RiteSync Guide_new.docx', '_split_id': 6, 'vector_id': '40'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'dd09bd0bf5a2a8030e043fc1c91690fa'}>, <Document: {'content': 'Cloud Integrator Configuration :\\n\\nPlace the Cloud Connector JAR in /home/ritesync/ritesynccloudintegretor\\nAfter placing the jar Go to config dir and create a file like below,\\n\\n$ cd /home/ritesync/ritesynccloudintegretor/config\\n\\n$ vi application.properties\\n\\nSave and exit the file\\n\\nLoader service Configuration :\\n\\nPlace the Loader service JAR in /home/ritesync/loaderservice dir\\nAfter Placing the jar go to ‘config’ dir and create a file.\\n\\n$ cd /home/ritesync/loaderservice/config\\n\\n$ vi application.properties\\n\\nSave and exit the file\\n\\nCreating Systemd Unit File and Starting the Ritesync Server\\n\\nIn this section, you will create systemd unit file for the Ritesync service. ', 'content_type': 'text', 'score': 0.5284455040406097, 'meta': {'name': 'RiteSync Guide_new.docx', '_split_id': 5, 'vector_id': '37'}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ccba28858d4853fdb573a2e59eeaa6f4'}>], 'root_node': 'Query', 'params': {'Retriever': {'top_k': 10}, 'Reader': {'top_k': 5}}, 'node_id': 'Reader'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: what is pod\n",
      "Answers:\n",
      "[   {   'answer': 'independent',\n",
      "        'context': 'earch for POD – click on add at lookup values – add POD\\n'\n",
      "                   'name. (POD is independent- doesn’t rely on any other '\n",
      "                   'values) – save.\\n'\n",
      "                   '➢ Export CSV – Export CSV'},\n",
      "    {   'answer': 'Product Oriented Delivery',\n",
      "        'context': 'ject code) are\\n'\n",
      "                   'Master data.\\n'\n",
      "                   'STEP 1:\\n'\n",
      "                   'Creation of POD:\\n'\n",
      "                   'POD - The Product Oriented Delivery (POD) model is a '\n",
      "                   'software development strategy that centers o'},\n",
      "    {   'answer': 'Project',\n",
      "        'context': 'left- admin – role object.\\x0c'\n",
      "                   '- User Manual | Confidential Page | 8\\n'\n",
      "                   '• Select the role name as admin, required POD, Project, '\n",
      "                   'parent object – Enable flag. '},\n",
      "    {   'answer': 'Project is related to POD – Hence select the required POD – '\n",
      "                  'Save',\n",
      "        'context': 's.\\x0c'\n",
      "                   '- User Manual | Confidential Page | 5\\n'\n",
      "                   '• Project is related to POD – Hence select the required '\n",
      "                   'POD – Save.\\n'\n",
      "                   'Creation of Parent Object:\\n'\n",
      "                   '• Click on the'},\n",
      "    {   'answer': 'Copy project',\n",
      "        'context': 'onment will be assigned to the\\n'\n",
      "                   'project and object in this screen).\\n'\n",
      "                   '➢ Copy project is used to copy the complete project with '\n",
      "                   'same data into a different'}]\n",
      "[{'answer': 'independent', 'context': 'earch for POD – click on add at lookup values – add POD\\nname. (POD is independent- doesn’t rely on any other values) – save.\\n➢ Export CSV – Export CSV'}, {'answer': 'Product Oriented Delivery', 'context': 'ject code) are\\nMaster data.\\nSTEP 1:\\nCreation of POD:\\nPOD - The Product Oriented Delivery (POD) model is a software development strategy that centers o'}, {'answer': 'Project', 'context': 'left- admin – role object.\\x0c- User Manual | Confidential Page | 8\\n• Select the role name as admin, required POD, Project, parent object – Enable flag. '}, {'answer': 'Project is related to POD – Hence select the required POD – Save', 'context': 's.\\x0c- User Manual | Confidential Page | 5\\n• Project is related to POD – Hence select the required POD – Save.\\nCreation of Parent Object:\\n• Click on the'}, {'answer': 'Copy project', 'context': 'onment will be assigned to the\\nproject and object in this screen).\\n➢ Copy project is used to copy the complete project with same data into a different'}]\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import print_answers\n",
    "\n",
    "temp = print_answers(prediction,details=\"minimum\" )## Choose from `minimum`, `medium`, and `all`\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of answer in dictionary {'answer': 'independent', 'context': 'earch for POD – click on add at lookup values – add POD\\nname. (POD is independent- doesn’t rely on any other values) – save.\\n➢ Export CSV – Export CSV'} is of type <class 'bytes'>\n",
      "The value of context in dictionary {'answer': 'independent', 'context': 'earch for POD – click on add at lookup values – add POD\\nname. (POD is independent- doesn’t rely on any other values) – save.\\n➢ Export CSV – Export CSV'} is of type <class 'bytes'>\n",
      "The value of answer in dictionary {'answer': 'Product Oriented Delivery', 'context': 'ject code) are\\nMaster data.\\nSTEP 1:\\nCreation of POD:\\nPOD - The Product Oriented Delivery (POD) model is a software development strategy that centers o'} is of type <class 'bytes'>\n",
      "The value of context in dictionary {'answer': 'Product Oriented Delivery', 'context': 'ject code) are\\nMaster data.\\nSTEP 1:\\nCreation of POD:\\nPOD - The Product Oriented Delivery (POD) model is a software development strategy that centers o'} is of type <class 'bytes'>\n",
      "The value of answer in dictionary {'answer': 'Project', 'context': 'left- admin – role object.\\x0c- User Manual | Confidential Page | 8\\n• Select the role name as admin, required POD, Project, parent object – Enable flag. '} is of type <class 'bytes'>\n",
      "The value of context in dictionary {'answer': 'Project', 'context': 'left- admin – role object.\\x0c- User Manual | Confidential Page | 8\\n• Select the role name as admin, required POD, Project, parent object – Enable flag. '} is of type <class 'bytes'>\n",
      "The value of answer in dictionary {'answer': 'Project is related to POD – Hence select the required POD – Save', 'context': 's.\\x0c- User Manual | Confidential Page | 5\\n• Project is related to POD – Hence select the required POD – Save.\\nCreation of Parent Object:\\n• Click on the'} is of type <class 'bytes'>\n",
      "The value of context in dictionary {'answer': 'Project is related to POD – Hence select the required POD – Save', 'context': 's.\\x0c- User Manual | Confidential Page | 5\\n• Project is related to POD – Hence select the required POD – Save.\\nCreation of Parent Object:\\n• Click on the'} is of type <class 'bytes'>\n",
      "The value of answer in dictionary {'answer': 'Copy project', 'context': 'onment will be assigned to the\\nproject and object in this screen).\\n➢ Copy project is used to copy the complete project with same data into a different'} is of type <class 'bytes'>\n",
      "The value of context in dictionary {'answer': 'Copy project', 'context': 'onment will be assigned to the\\nproject and object in this screen).\\n➢ Copy project is used to copy the complete project with same data into a different'} is of type <class 'bytes'>\n",
      "[{'answer': 'independent', 'context': 'earch for POD – click on add at lookup values – add POD\\nname. (POD is independent- doesn’t rely on any other values) – save.\\n➢ Export CSV – Export CSV'}, {'answer': 'Product Oriented Delivery', 'context': 'ject code) are\\nMaster data.\\nSTEP 1:\\nCreation of POD:\\nPOD - The Product Oriented Delivery (POD) model is a software development strategy that centers o'}, {'answer': 'Project', 'context': 'left- admin – role object.\\x0c- User Manual | Confidential Page | 8\\n• Select the role name as admin, required POD, Project, parent object – Enable flag. '}, {'answer': 'Project is related to POD – Hence select the required POD – Save', 'context': 's.\\x0c- User Manual | Confidential Page | 5\\n• Project is related to POD – Hence select the required POD – Save.\\nCreation of Parent Object:\\n• Click on the'}, {'answer': 'Copy project', 'context': 'onment will be assigned to the\\nproject and object in this screen).\\n➢ Copy project is used to copy the complete project with same data into a different'}]\n"
     ]
    }
   ],
   "source": [
    "for i in temp:\n",
    "        for key, value in i.items():\n",
    "            value = value.encode(\"utf-8\")\n",
    "            print(f\"The value of {key} in dictionary {i} is of type {type(value)}\")\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar  7 12:54:45 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 522.25       Driver Version: 522.25       CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   63C    P8    N/A /  N/A |      0MiB /  4096MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have a GPU running\n",
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb79ba29542c144dd811710a33c3f672d46a730a07e871a5c60f51fcfe992ed4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
